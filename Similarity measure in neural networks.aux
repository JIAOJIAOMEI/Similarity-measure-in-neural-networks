\relax 
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Similarity measure in neural networks}{2}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Distance and similarity}{2}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1.1}{\ignorespaces Features\relax }}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Similarity in Binary Classification}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Linear regression}{3}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Linear regression\relax }}{3}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Loss is the summation of the difference between y and predicted y\relax }}{3}{}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:loss1}{{1.2}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces Distance: vertical and horizontal\relax }}{4}{}\protected@file@percent }
\newlabel{fig:loss2}{{1.3}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}Logistic regression}{4}{}\protected@file@percent }
\newlabel{eq:binary1}{{1.1}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces Binary classification\relax }}{4}{}\protected@file@percent }
\newlabel{fig:binary1}{{1.4}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces Binary classification\relax }}{5}{}\protected@file@percent }
\newlabel{fig:binary2}{{1.5}{5}}
\newlabel{eq:binary2}{{1.2}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.6}{\ignorespaces Cat and Dog\relax }}{5}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.7}{\ignorespaces Decision boundary\relax }}{6}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.3}Some other Classification methods}{6}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.8}{\ignorespaces Decision boundary by different classifiers\relax }}{6}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Similarity in Covlutional Neural Networks(CNN)}{7}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.9}{\ignorespaces CNN\relax }}{7}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.10}{\ignorespaces Dot product and similarity\relax }}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Similarity in Deep Neural Networks(DNN)}{8}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.11}{\ignorespaces CNN and DNN\relax }}{8}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Similarity in Attention Mechanism}{8}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.12}{\ignorespaces Attention for machine translation where $Q$ is the hidden state of the decoder, $K$ and $V$ are the hidden states of the encoder.\relax }}{9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.6}Self-attention}{9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.7}Multi-head Attention and Transformer model}{10}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.13}{\ignorespaces Multi-head attention\relax }}{10}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.14}{\ignorespaces Transformer\relax }}{10}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.8}Vision Transformer}{11}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.9}Conclusion}{11}{}\protected@file@percent }
\gdef \@abspage@last{11}
